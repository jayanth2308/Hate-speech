{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788cc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82655317",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df69b040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b5d6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "count                 0\n",
       "hate_speech           0\n",
       "offensive_language    0\n",
       "neither               0\n",
       "class                 0\n",
       "tweet                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dbaaf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          24783 non-null  int64 \n",
      " 1   count               24783 non-null  int64 \n",
      " 2   hate_speech         24783 non-null  int64 \n",
      " 3   offensive_language  24783 non-null  int64 \n",
      " 4   neither             24783 non-null  int64 \n",
      " 5   class               24783 non-null  int64 \n",
      " 6   tweet               24783 non-null  object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588a6578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12681.192027</td>\n",
       "      <td>3.243473</td>\n",
       "      <td>0.280515</td>\n",
       "      <td>2.413711</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>1.110277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7299.553863</td>\n",
       "      <td>0.883060</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>1.399459</td>\n",
       "      <td>1.113299</td>\n",
       "      <td>0.462089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6372.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12703.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18995.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25296.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         count   hate_speech  offensive_language  \\\n",
       "count  24783.000000  24783.000000  24783.000000        24783.000000   \n",
       "mean   12681.192027      3.243473      0.280515            2.413711   \n",
       "std     7299.553863      0.883060      0.631851            1.399459   \n",
       "min        0.000000      3.000000      0.000000            0.000000   \n",
       "25%     6372.500000      3.000000      0.000000            2.000000   \n",
       "50%    12703.000000      3.000000      0.000000            3.000000   \n",
       "75%    18995.500000      3.000000      0.000000            3.000000   \n",
       "max    25296.000000      9.000000      7.000000            9.000000   \n",
       "\n",
       "            neither         class  \n",
       "count  24783.000000  24783.000000  \n",
       "mean       0.549247      1.110277  \n",
       "std        1.113299      0.462089  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      1.000000  \n",
       "50%        0.000000      1.000000  \n",
       "75%        0.000000      1.000000  \n",
       "max        9.000000      2.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91fb0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['labels']=dataset['class'].map ({0: \"Hate speech\",\n",
    "                                       1: \"Offensive language\",\n",
    "                                       2: \"No hate or Offensive language\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31542152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...   \n",
       "24779  you've gone and broke the wrong heart baby, an...   \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...   \n",
       "24781              youu got wild bitches tellin you lies   \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...   \n",
       "\n",
       "                              labels  \n",
       "0      No hate or Offensive language  \n",
       "1                 Offensive language  \n",
       "2                 Offensive language  \n",
       "3                 Offensive language  \n",
       "4                 Offensive language  \n",
       "...                              ...  \n",
       "24778             Offensive language  \n",
       "24779  No hate or Offensive language  \n",
       "24780             Offensive language  \n",
       "24781             Offensive language  \n",
       "24782  No hate or Offensive language  \n",
       "\n",
       "[24783 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7aec53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[[\"tweet\",\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48097102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...   \n",
       "24779  you've gone and broke the wrong heart baby, an...   \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...   \n",
       "24781              youu got wild bitches tellin you lies   \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...   \n",
       "\n",
       "                              labels  \n",
       "0      No hate or Offensive language  \n",
       "1                 Offensive language  \n",
       "2                 Offensive language  \n",
       "3                 Offensive language  \n",
       "4                 Offensive language  \n",
       "...                              ...  \n",
       "24778             Offensive language  \n",
       "24779  No hate or Offensive language  \n",
       "24780             Offensive language  \n",
       "24781             Offensive language  \n",
       "24782  No hate or Offensive language  \n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6abe5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2213b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing stop words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "stopwords.add('rt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70bce407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stemming\n",
    "stemmer = nltk.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d47cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "def clean_data(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('https?://\\S+|www\\.S+','',text)\n",
    "    text = re.sub('\\[.*?\\]','',text)\n",
    "    text = re.sub('<.*?>+','',text)\n",
    "    text = re.sub('[%s]' %re.escape(string.punctuation),'',text)\n",
    "    text = re.sub('\\n','',text)\n",
    "    text = re.sub('\\w*\\d\\w*','',text)\n",
    "    #stop words removal\n",
    "    text = [word for word in text.split(' ') if word not in stopwords]\n",
    "    text = \" \".join(text)\n",
    "    #stemming the text\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "471abd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kykne\\AppData\\Local\\Temp\\ipykernel_33608\\1832165696.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"tweet\"] = data[\"tweet\"].apply(clean_data)\n"
     ]
    }
   ],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "704efd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mayasolov woman shouldnt complain clean hous ...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy dat coldtyga dwn bad cuffin dat hoe  place</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urkindofbrand dawg  ever fuck bitch start cri...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cganderson vivabas look like tranni</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shenikarobert shit hear might true might fake...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>yous muthafin lie   coreyemanuel right tl tras...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>youv gone broke wrong heart babi drove redneck...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat dat nigguh like aint fuck...</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitch tellin lie</td>\n",
       "      <td>Offensive language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>ruffl  ntac eileen dahlia  beauti color combin...</td>\n",
       "      <td>No hate or Offensive language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "0       mayasolov woman shouldnt complain clean hous ...   \n",
       "1         boy dat coldtyga dwn bad cuffin dat hoe  place   \n",
       "2       urkindofbrand dawg  ever fuck bitch start cri...   \n",
       "3                    cganderson vivabas look like tranni   \n",
       "4       shenikarobert shit hear might true might fake...   \n",
       "...                                                  ...   \n",
       "24778  yous muthafin lie   coreyemanuel right tl tras...   \n",
       "24779  youv gone broke wrong heart babi drove redneck...   \n",
       "24780  young buck wanna eat dat nigguh like aint fuck...   \n",
       "24781                     youu got wild bitch tellin lie   \n",
       "24782  ruffl  ntac eileen dahlia  beauti color combin...   \n",
       "\n",
       "                              labels  \n",
       "0      No hate or Offensive language  \n",
       "1                 Offensive language  \n",
       "2                 Offensive language  \n",
       "3                 Offensive language  \n",
       "4                 Offensive language  \n",
       "...                              ...  \n",
       "24778             Offensive language  \n",
       "24779  No hate or Offensive language  \n",
       "24780             Offensive language  \n",
       "24781             Offensive language  \n",
       "24782  No hate or Offensive language  \n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52fc1fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[\"tweet\"])\n",
    "y=  np.array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e833e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' mayasolov woman shouldnt complain clean hous amp man alway take trash',\n",
       "       '  boy dat coldtyga dwn bad cuffin dat hoe  place',\n",
       "       ' urkindofbrand dawg  ever fuck bitch start cri confus shit', ...,\n",
       "       'young buck wanna eat dat nigguh like aint fuckin dis',\n",
       "       'youu got wild bitch tellin lie',\n",
       "       'ruffl  ntac eileen dahlia  beauti color combin pink orang yellow amp white coll '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a038f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e41c3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a54f018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24783x25692 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 190738 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6113fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6242a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44142f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "466954f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1abcdc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building out the model\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f3b5fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b920a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cc57a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 177,   38,  250],\n",
       "       [  35, 1140,  204],\n",
       "       [ 243,  237, 5855]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix and its accuracy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95c06e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as ply\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "339ef90b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1111175172.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[35], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    sns.heatmap(cm, annot=True, fmt=\".1f\", smaple)\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, fmt=\".1f\", smaple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b615e8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87687981415821"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "263fa472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\kykne\\anaconda3\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.25.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kykne\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfcd45b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\kykne\\anaconda3\\lib\\site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "396d85c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming 'data.csv' has columns 'tweet' and 'class'\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# Add labels to the dataset\n",
    "dataset['labels'] = dataset['class'].map({0: \"Hate speech\", 1: \"Offensive language\", 2: \"No hate or Offensive language\"})\n",
    "\n",
    "# Select relevant data\n",
    "data = dataset[['tweet', 'labels']]\n",
    "\n",
    "# Tokenize and pad the sequences\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "tokenizer.fit_on_texts(data['tweet'].values)\n",
    "X_deep = tokenizer.texts_to_sequences(data['tweet'].values)\n",
    "X_deep = pad_sequences(X_deep)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_deep_train, X_deep_test, y_train, y_test = train_test_split(X_deep, data['labels'], test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Verify data types\n",
    "print(y_train_encoded.dtype)\n",
    "print(y_test_encoded.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c259973a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Offensive language'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_train_encoded \u001b[38;5;241m=\u001b[39m \u001b[43my_train_encoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m y_test_encoded\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Offensive language'"
     ]
    }
   ],
   "source": [
    "y_train_encoded = y_train_encoded.astype(int)\n",
    "y_test_encoded = y_test_encoded.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acf7f4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Offensive language', 'No hate or Offensive language', 'Hate speech'}\n",
      "{'Offensive language', 'No hate or Offensive language', 'Hate speech'}\n"
     ]
    }
   ],
   "source": [
    "print(set(y_train))\n",
    "print(set(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2ad81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train.astype(str))\n",
    "y_test_encoded = label_encoder.transform(y_test.astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90c05abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "260/260 [==============================] - 46s 170ms/step - loss: 0.4559 - accuracy: 0.8413 - val_loss: 0.3106 - val_accuracy: 0.8931\n",
      "Epoch 2/5\n",
      "260/260 [==============================] - 31s 120ms/step - loss: 0.2403 - accuracy: 0.9175 - val_loss: 0.2883 - val_accuracy: 0.8945\n",
      "Epoch 3/5\n",
      "260/260 [==============================] - 40s 155ms/step - loss: 0.1828 - accuracy: 0.9366 - val_loss: 0.3118 - val_accuracy: 0.8969\n",
      "Epoch 4/5\n",
      "260/260 [==============================] - 46s 178ms/step - loss: 0.1522 - accuracy: 0.9466 - val_loss: 0.3449 - val_accuracy: 0.8956\n",
      "Epoch 5/5\n",
      "260/260 [==============================] - 46s 178ms/step - loss: 0.1255 - accuracy: 0.9566 - val_loss: 0.3887 - val_accuracy: 0.8826\n",
      "256/256 [==============================] - 4s 16ms/step - loss: 0.3887 - accuracy: 0.8826\n",
      "Deep Learning Model Accuracy: 88.26%\n",
      "Epoch 1/5\n",
      "260/260 [==============================] - 38s 146ms/step - loss: 0.1071 - accuracy: 0.9623 - val_loss: 0.4284 - val_accuracy: 0.8847\n",
      "Epoch 2/5\n",
      "260/260 [==============================] - 40s 156ms/step - loss: 0.0900 - accuracy: 0.9686 - val_loss: 0.4561 - val_accuracy: 0.8820\n",
      "Epoch 3/5\n",
      "260/260 [==============================] - 44s 171ms/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 0.4808 - val_accuracy: 0.8809\n",
      "Epoch 4/5\n",
      "260/260 [==============================] - 44s 170ms/step - loss: 0.0718 - accuracy: 0.9743 - val_loss: 0.5129 - val_accuracy: 0.8741\n",
      "Epoch 5/5\n",
      "260/260 [==============================] - 43s 166ms/step - loss: 0.0605 - accuracy: 0.9783 - val_loss: 0.5461 - val_accuracy: 0.8757\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.5461 - accuracy: 0.8757\n",
      "Deep Learning Model Accuracy: 87.57%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenize and pad the sequences\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "tokenizer.fit_on_texts(data['tweet'].values)\n",
    "X_deep = tokenizer.texts_to_sequences(data['tweet'].values)\n",
    "X_deep = pad_sequences(X_deep)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_deep_train, X_deep_test, y_train_encoded, y_test_encoded = train_test_split(X_deep, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Build the deep learning model\n",
    "embedding_dim = 100\n",
    "model_deep = Sequential()\n",
    "model_deep.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=X_deep.shape[1]))\n",
    "model_deep.add(SpatialDropout1D(0.2))\n",
    "model_deep.add(LSTM(100))\n",
    "model_deep.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_deep.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the modelfrom tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ... (Previous code for loading and preprocessing data)\n",
    "\n",
    "# Update label encoding to handle non-numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train.astype(str))\n",
    "y_test_encoded = label_encoder.transform(y_test.astype(str))\n",
    "\n",
    "# Build the deep learning model\n",
    "embedding_dim = 100\n",
    "model_deep = Sequential()\n",
    "model_deep.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=X_deep.shape[1]))\n",
    "model_deep.add(SpatialDropout1D(0.2))\n",
    "model_deep.add(LSTM(100))\n",
    "model_deep.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_deep.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "model_deep.fit(X_deep_train, y_train_encoded, validation_data=(X_deep_test, y_test_encoded), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the deep learning model\n",
    "loss, accuracy = model_deep.evaluate(X_deep_test, y_test_encoded, verbose=1)\n",
    "print(f\"Deep Learning Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "model_deep.fit(X_deep_train, y_train_encoded, validation_data=(X_deep_test, y_test_encoded), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the deep learning model\n",
    "loss, accuracy = model_deep.evaluate(X_deep_test, y_test_encoded, verbose=1)\n",
    "print(f\"Deep Learning Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7960eb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "260/260 [==============================] - 7s 26ms/step - loss: 0.4581 - accuracy: 0.8451 - val_loss: 0.2947 - val_accuracy: 0.9037\n",
      "Epoch 2/5\n",
      "260/260 [==============================] - 6s 24ms/step - loss: 0.2598 - accuracy: 0.9143 - val_loss: 0.2701 - val_accuracy: 0.9043\n",
      "Epoch 3/5\n",
      "260/260 [==============================] - 6s 24ms/step - loss: 0.1869 - accuracy: 0.9342 - val_loss: 0.2902 - val_accuracy: 0.9023\n",
      "Epoch 4/5\n",
      "260/260 [==============================] - 8s 32ms/step - loss: 0.1198 - accuracy: 0.9576 - val_loss: 0.3856 - val_accuracy: 0.8945\n",
      "Epoch 5/5\n",
      "260/260 [==============================] - 8s 31ms/step - loss: 0.0719 - accuracy: 0.9758 - val_loss: 0.4470 - val_accuracy: 0.8897\n",
      "256/256 [==============================] - 2s 8ms/step - loss: 0.4470 - accuracy: 0.8897\n",
      "CNN Model Accuracy: 88.97%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tokenize and pad the sequences\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "tokenizer.fit_on_texts(data['tweet'].values)\n",
    "X_deep = tokenizer.texts_to_sequences(data['tweet'].values)\n",
    "X_deep = pad_sequences(X_deep)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_deep_train, X_deep_test, y_train, y_test = train_test_split(X_deep, data['labels'], test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train.astype(str))\n",
    "y_test_encoded = label_encoder.transform(y_test.astype(str))\n",
    "\n",
    "# Build the CNN model\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=X_deep.shape[1]))\n",
    "model_cnn.add(Conv1D(128, 5, activation='relu'))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_cnn.fit(X_deep_train, y_train_encoded, validation_data=(X_deep_test, y_test_encoded), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the CNN model\n",
    "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_deep_test, y_test_encoded, verbose=1)\n",
    "print(f\"CNN Model Accuracy: {accuracy_cnn * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2117f28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
